{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#ImageDataGenerator\" data-toc-modified-id=\"ImageDataGenerator-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>ImageDataGenerator</a></span></li></ul></li><li><span><a href=\"#Preprocessing-images\" data-toc-modified-id=\"Preprocessing-images-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-image-data-from-the-hierarchical-file-'chest_xray'-using-an-image-datagenerator\" data-toc-modified-id=\"Load-image-data-from-the-hierarchical-file-'chest_xray'-using-an-image-datagenerator-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load image data from the hierarchical file 'chest_xray' using an image datagenerator</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-the-X,y-of-Dataset\" data-toc-modified-id=\"Define-the-X,y-of-Dataset-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Define the X,y of Dataset</a></span></li><li><span><a href=\"#Build-Base-Model\" data-toc-modified-id=\"Build-Base-Model-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Build Base Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Designing-the-CNN\" data-toc-modified-id=\"Designing-the-CNN-1.1.2.1\"><span class=\"toc-item-num\">1.1.2.1&nbsp;&nbsp;</span>Designing the CNN</a></span></li></ul></li><li><span><a href=\"#Pooling-Layer:\" data-toc-modified-id=\"Pooling-Layer:-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Pooling Layer:</a></span></li><li><span><a href=\"#Training-and-Evaluating-the-Model\" data-toc-modified-id=\"Training-and-Evaluating-the-Model-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Training and Evaluating the Model</a></span></li></ul></li><li><span><a href=\"#Severe-OverFitting\" data-toc-modified-id=\"Severe-OverFitting-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Severe OverFitting</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:41:35.352907Z",
     "start_time": "2020-06-21T19:41:31.325114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from random import sample\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models,layers\n",
    "from tensorflow.keras.layers import Input, Lambda, Flatten,Activation, Dense, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import models,layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:55:38.589624Z",
     "start_time": "2020-06-19T02:55:38.559889Z"
    }
   },
   "source": [
    "### ImageDataGenerator\n",
    "https://keras.io/api/preprocessing/image/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing images\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image data from the hierarchical file 'chest_xray' using an image datagenerator\n",
    "* Load images\n",
    "* Read the picture files\n",
    "* define testing,training , validation.\n",
    "* Decode the JPEG content to RGB grids of pixels.\n",
    "* reshape all images to same size of  28 x 28 pixels \n",
    "* Convert pixels into floating point tensors\n",
    "* chuck data by \"batch_size=32'\n",
    "* Rescale the pixel values( between o and 255) to the [0,1] interval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:41:35.384433Z",
     "start_time": "2020-06-21T19:41:35.367799Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime\n",
    "original_start = datetime.datetime.now()\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:43:36.575386Z",
     "start_time": "2020-06-21T19:43:36.571998Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_dir =('/Users/khuloodnasher/dsc-mod-4-project-v2-1-onl01-dtsc-ft-030220/data/train')\n",
    "test_data_dir =('/Users/khuloodnasher/dsc-mod-4-project-v2-1-onl01-dtsc-ft-030220/data/test')\n",
    "val_data_dir =('/Users/khuloodnasher/dsc-mod-4-project-v2-1-onl01-dtsc-ft-030220/data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:43:45.633401Z",
     "start_time": "2020-06-21T19:43:45.174316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get all the data in the directory data/test , and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(test_data_dir,\n",
    "        target_size=(64, 64), batch_size=32,class_mode = 'binary')\n",
    "# Get all the data in the directory data/train, and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(train_data_dir,\n",
    "        target_size=(64, 64), batch_size=32,class_mode = 'binary')\n",
    "# Get all the data in the directory data/val, and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(val_data_dir,\n",
    "        target_size=(64, 64), batch_size=32,class_mode = 'binary')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:44:18.239369Z",
     "start_time": "2020-06-21T19:44:17.202880Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the data sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:45:20.898178Z",
     "start_time": "2020-06-21T19:45:20.721929Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "#Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)))\n",
    "#Pooling\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# 2nd Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "# 2nd Pooling layer\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Flatten the layer\n",
    "cnn.add(Flatten())\n",
    "# Fully Connected Layers\n",
    "cnn.add(Dense(activation = 'relu', units = 512))\n",
    "cnn.add(Dense(activation = 'sigmoid', units = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:46:00.516532Z",
     "start_time": "2020-06-21T19:46:00.447947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,222,433\n",
      "Trainable params: 3,222,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the Neural network\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:53:42.896029Z",
     "start_time": "2020-06-21T19:46:30.133562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 165s 2s/step - loss: 0.3201 - accuracy: 0.8603 - val_loss: 0.3834 - val_accuracy: 0.8750\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.1381 - accuracy: 0.9472 - val_loss: 0.2579 - val_accuracy: 0.9375\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 161s 2s/step - loss: 0.1137 - accuracy: 0.9603 - val_loss: 0.4141 - val_accuracy: 0.7500\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 158s 2s/step - loss: 0.1007 - accuracy: 0.9663 - val_loss: 0.1843 - val_accuracy: 0.9375\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 157s 2s/step - loss: 0.0824 - accuracy: 0.9700 - val_loss: 0.1579 - val_accuracy: 1.0000\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 157s 2s/step - loss: 0.0784 - accuracy: 0.9734 - val_loss: 0.2707 - val_accuracy: 0.8750\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 163s 2s/step - loss: 0.0557 - accuracy: 0.9791 - val_loss: 0.4998 - val_accuracy: 0.8125\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 159s 2s/step - loss: 0.0670 - accuracy: 0.9753 - val_loss: 0.4040 - val_accuracy: 0.7500\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 157s 2s/step - loss: 0.0476 - accuracy: 0.9828 - val_loss: 0.1950 - val_accuracy: 0.8750\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.0491 - accuracy: 0.9797 - val_loss: 0.2149 - val_accuracy: 0.9375\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 157s 2s/step - loss: 0.0444 - accuracy: 0.9809 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.0470 - accuracy: 0.9822 - val_loss: 0.1260 - val_accuracy: 0.9375\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 157s 2s/step - loss: 0.0453 - accuracy: 0.9800 - val_loss: 0.3709 - val_accuracy: 0.8125\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 158s 2s/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.1152 - val_accuracy: 0.9375\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.1394 - val_accuracy: 0.8750\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.0179 - accuracy: 0.9931 - val_loss: 0.7997 - val_accuracy: 0.8125\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 161s 2s/step - loss: 0.0178 - accuracy: 0.9931 - val_loss: 0.6891 - val_accuracy: 0.8125\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 163s 2s/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.2679 - val_accuracy: 0.8750\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 172s 2s/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.1683 - val_accuracy: 0.9375\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.5107 - val_accuracy: 0.8750\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 172s 2s/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.1979 - val_accuracy: 0.8750\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 168s 2s/step - loss: 0.0138 - accuracy: 0.9937 - val_loss: 0.4104 - val_accuracy: 0.8750\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 164s 2s/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 1.3259 - val_accuracy: 0.6875\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 163s 2s/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.6750 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "cnn_history = cnn.fit_generator(train_generator,\n",
    "                         steps_per_epoch = 100,\n",
    "                         epochs = 25,\n",
    "                         validation_data = val_generator,\n",
    "                         validation_steps = 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T18:52:52.879279Z",
     "start_time": "2020-06-21T18:52:52.553965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#### Load images\n",
    "train_dir =('/Users/khuloodnasher/Documents/Flatiorn/imageclassification/image-classification-project/chest_xray/train')\n",
    "test_dir =('/Users/khuloodnasher/Documents/Flatiorn/imageclassification/image-classification-project/chest_xray/test')\n",
    "validation_dir =('/Users/khuloodnasher/Documents/Flatiorn/imageclassification/image-classification-project/chest_xray/val')\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(64, 64),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the X,y of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T18:52:52.886180Z",
     "start_time": "2020-06-21T18:52:52.883240Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the data sets\n",
    "#train_images, train_labels = next(train_generator)\n",
    "#test_images, test_labels = next(test_generator)\n",
    "#val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Base Model \n",
    "##### Designing the CNN\n",
    "###### To design CNN using Keras,we must consider the following:\n",
    "\n",
    "* alternate convolutional and pooling layers.\n",
    "\n",
    "* have later layers having a larger number of parameters in order to detect more abstract patterns.\n",
    "\n",
    "* Add some final dense layers to add a classifier to the convolutional base.\n",
    "\n",
    "* Compile this model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling Layer:\n",
    "Pooling layers goal is to subsample (i.e., shrink) the input image in order to reduce the computational load, the memory usage, and the number of parameters (thereby limiting the risk of overfitting)\n",
    "1. Max pooling: The maximum pixel value of the batch is selected.\n",
    "2. Average pooling: The average value of all the pixels in the batch is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T18:52:53.107424Z",
     "start_time": "2020-06-21T18:52:52.889065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Always start the model with sequebtial function\n",
    "model = models.Sequential()\n",
    "\n",
    "# start adding layers and define the activation function of each layer as' relu', we define images in size 150x150\n",
    "# in keras function for the convolution step is Conv2D\n",
    "\n",
    "# input layer\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#  First Hidden \n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Second Hidden Layer\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#  Third Hidden Layer\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#Change all the layers dimension to vector through Fltten function\n",
    "model.add(layers.Flatten())\n",
    "# Adding the last layer before the output layer\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "# Adding the output layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compiling  and Optimizing base model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T18:52:53.114594Z",
     "start_time": "2020-06-21T18:52:53.109026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 504,001\n",
      "Trainable params: 504,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To get the number of parameters that i'm going to learn using the above architicure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Evaluating the Model\n",
    " Training deep networks is resource intensive: depending on the size of the data, even a CNN with 3-4 successive \n",
    " \n",
    " convolutional and pooling layers tend to take  hours to train. \n",
    " \n",
    " Using 30 epochs and 8 layers (alternating between convolutional and pooling), our model took about 40 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:07:44.111480Z",
     "start_time": "2020-06-21T18:52:53.117110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.5415 - acc: 0.7500 - val_loss: 0.8047 - val_acc: 0.5625\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 60s 595ms/step - loss: 0.3877 - acc: 0.8213 - val_loss: 0.9015 - val_acc: 0.6250\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 60s 596ms/step - loss: 0.3100 - acc: 0.8628 - val_loss: 1.2263 - val_acc: 0.6250\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 60s 597ms/step - loss: 0.2657 - acc: 0.8847 - val_loss: 0.8716 - val_acc: 0.6250\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 59s 588ms/step - loss: 0.2488 - acc: 0.8959 - val_loss: 1.2822 - val_acc: 0.6250\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 59s 590ms/step - loss: 0.2205 - acc: 0.9100 - val_loss: 0.8608 - val_acc: 0.6250\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 59s 590ms/step - loss: 0.1818 - acc: 0.9272 - val_loss: 0.4767 - val_acc: 0.8750\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 60s 599ms/step - loss: 0.1904 - acc: 0.9272 - val_loss: 0.4631 - val_acc: 0.8750\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 59s 592ms/step - loss: 0.1516 - acc: 0.9422 - val_loss: 0.5793 - val_acc: 0.8125\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 61s 606ms/step - loss: 0.1430 - acc: 0.9409 - val_loss: 1.6800 - val_acc: 0.5625\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 59s 590ms/step - loss: 0.1320 - acc: 0.9516 - val_loss: 1.1078 - val_acc: 0.5625\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 58s 583ms/step - loss: 0.1133 - acc: 0.9531 - val_loss: 1.1447 - val_acc: 0.5625\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 58s 584ms/step - loss: 0.1098 - acc: 0.9591 - val_loss: 0.8169 - val_acc: 0.6250\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 59s 592ms/step - loss: 0.0979 - acc: 0.9650 - val_loss: 0.5307 - val_acc: 0.7500\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 60s 596ms/step - loss: 0.0976 - acc: 0.9625 - val_loss: 0.8279 - val_acc: 0.6250\n"
     ]
    }
   ],
   "source": [
    "# fitting my base_model with training data \n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=100, \n",
    "                              epochs=15, \n",
    "                              validation_data=validation_generator, \n",
    "                              validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:07:44.125899Z",
     "start_time": "2020-06-21T19:07:44.118161Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_train = model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:07:44.133118Z",
     "start_time": "2020-06-21T19:07:44.129432Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_test = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:07:44.137894Z",
     "start_time": "2020-06-21T19:07:44.135599Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T19:07:44.142326Z",
     "start_time": "2020-06-21T19:07:44.139991Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.097Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.099Z"
    }
   },
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.102Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.104Z"
    }
   },
   "outputs": [],
   "source": [
    "rain_datagen = ImageDataGenerator(rotation_range=40, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, \n",
    "                                                        target_size=(150, 150), \n",
    "                                                        batch_size=32, \n",
    "                                                        class_mode='binary')\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=100, \n",
    "                              epochs=100, \n",
    "                              validation_data=validation_generator, \n",
    "                              validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.107Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.110Z"
    }
   },
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training with data augmentation took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.113Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                  target_size=(150, 150), \n",
    "                                                  batch_size=20, \n",
    "                                                  class_mode='binary')\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.120Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cnn = Sequential()\n",
    "#Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)))\n",
    "#Pooling\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# 2nd Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "# 2nd Pooling layer\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Flatten the layer\n",
    "cnn.add(Flatten())\n",
    "# Fully Connected Layers\n",
    "cnn.add(Dense(activation = 'relu', units = 512))\n",
    "cnn.add(Dense(activation = 'sigmoid', units = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the Neural network\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.126Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_history = cnn.fit_generator(train_generator,\n",
    "                         steps_per_epoch = 100,\n",
    "                         epochs = 25,\n",
    "                         validation_data = val_generator,\n",
    "                         validation_steps = 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.129Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_train = cnn.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.132Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_test = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.134Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T18:52:48.137Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severe OverFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process\n",
    "1. CNN with small dataset (Acc 71%)\n",
    "2. CNN with data augmentation (Acc 80+%)\n",
    "3. Transfer Learning (Acc 90+%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
